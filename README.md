# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?
#

1. Доступность HTTP-сервера
Метрики: Статус HTTP-сервера (up/down), код ответа HTTP (2xx, 4xx, 5xx), время ответа (latency).
Почему: Поскольку взаимодействие с платформой осуществляется по HTTP, важно отслеживать доступность и корректность работы HTTP-сервера. Метрики по коду ответа помогут выявить проблемы с доступностью и корректностью работы сервера.
2. Загрузка ЦПУ
Метрики: Средняя загрузка ЦПУ (CPU load average), использование ЦПУ в процентах (CPU usage %).
Почему: Вычисления, которые выполняет платформа, сильно загружают ЦПУ, поэтому важно отслеживать его использование. Если загрузка ЦПУ достигает критических значений, это может привести к ухудшению производительности или недоступности системы.
3. Использование диска
Метрики: Свободное место на диске (disk space available), использование диска в процентах (disk usage %).
Почему: Поскольку отчеты сохраняются на диск, важно отслеживать состояние хранилища. Недостаток свободного места на диске может привести к сбоям в работе системы или невозможности сохранения отчетов.


2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?
#

1. Метрика доступности сервиса (Service Availability)
Что измеряет: Процент времени, в течение которого сервис был доступен для пользователей.
2. Среднее время ответа (Average Response Time)
Что измеряет: Среднее время, за которое платформа обрабатывает запросы пользователей.
3. Успешность выполнения вычислений (Job Success Rate)
Что измеряет: Процент вычислений, завершившихся успешно.
4. Процент выполнения SLA (SLA Compliance Rate)
Что измеряет: Процент времени, в течение которого платформа соответствовала условиям соглашения об уровне обслуживания (SLA).
5. Процент ошибок (Error Rate)
Что измеряет: Доля запросов или вычислений, завершившихся с ошибкой.

3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?
#

- Можно рассмотреть использование бесплатных или опенсорсных инструментов для сбора и анализа логов, таких как ELK Stack (Elasticsearch, Logstash, Kibana), Graylog, или Fluentd. Хотя полноценная настройка этих систем может потребовать ресурсов, минимальная конфигурация может быть выполнена силами текущей команды без дополнительных затрат.
- Логирование в стандартный вывод (stdout) с перенаправлением в файлы. Если приложения разворачиваются в контейнерах (например, Docker), можно настроить контейнеры на запись логов в стандартный вывод (stdout). Эти логи затем могут быть автоматически собраны и сохранены в файл на хостовой машине.

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
#

Ошибка заключается в том, что не учитываются коды ответов HTTP, которые не попадают в диапазон 2xx, но при этом не являются ошибочными (4xx и 5xx). В HTTP существует несколько других категорий ответов, например 1xx и 3xx.
Если у нас значительное количество ответов с кодами 1xx или 3xx, это будет снижать ваш показатель SLA, так как они не включаются в число успешных 2xx-ответов. 
Формулу нужно уточнить. Например, мы можете рассматривать коды 2xx и 3xx как успешные: SLA = (summ_2xx_requests + summ_3xx_requests) / summ_all_requests

5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#

Pull-системы мониторинга
Плюсы:
- Централизованный контроль. Сервер мониторинга контролирует, какие метрики и как часто собираются, что упрощает управление мониторингом и конфигурацией.
- Безопасность. Сервер мониторинга инициирует соединения, что позволяет защитить серверы от случайных или нежелательных соединений. Это делает систему более безопасной, поскольку только доверенные узлы могут передавать данные.
- Гибкость настройки. Можно легко настроить частоту опроса для разных метрик или устройств, что позволяет оптимизировать нагрузку на сеть и системы.
- Легкость в управлении масштабированием. Новый узел можно легко добавить в систему мониторинга, просто настроив его на сервере мониторинга. Узлы не требуют конфигурации для отправки данных.
Минусы:
- Нагрузки на сервер мониторинга. При большом количестве узлов или метрик сервер мониторинга может испытывать высокую нагрузку из-за необходимости периодически опрашивать все системы.
- Проблемы с доступностью. Если сервер мониторинга недоступен или имеет проблемы с подключением к узлам, данные не будут собраны, что может привести к пропуску важных событий.
- Сложности с мониторингом динамических сред. В средах с часто меняющимися IP-адресами или с большим количеством кратковременно существующих объектов (например, контейнеров) может быть сложно настроить корректный сбор данных.

Push-системы мониторинга
Плюсы:
- Масштабируемость. Узлы сами отправляют данные, что снижает нагрузку на центральный сервер мониторинга, особенно в больших инфраструктурах.
- Реактивность. Узлы могут отправлять данные сразу при изменении состояния, что позволяет более оперативно реагировать на события.
- Поддержка динамических сред. Подходит для сред с динамически меняющейся архитектурой, таких как облачные инфраструктуры и контейнерные среды, где узлы могут быстро появляться и исчезать.
- Устойчивость к отказам сервера мониторинга. Если сервер мониторинга временно недоступен, узлы могут буферизовать данные и отправлять их позже, что помогает избежать потери данных.
Минусы:
- Распространение конфигурации. Каждый узел должен быть настроен для отправки данных, что может усложнять управление и увеличение количества узлов.
- Безопасность. Узлы должны быть настроены для отправки данных к серверу мониторинга, что может создать дополнительные риски безопасности, если данные отправляются через ненадежные сети.
- Проблемы с консистентностью данных. Если данные отправляются асинхронно, могут возникнуть проблемы с консистентностью метрик, особенно если данные отправляются с разных узлов в разное время.
- Сложность в управлении. Управление временем отправки и объемом данных может быть сложнее, особенно в крупных распределенных системах, где важно координировать отправку данных с разных узлов.

6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios
#

    - Prometheus - Pull
    - TICK - Push
    - Zabbix - Гибрид
    - VictoriaMetrics - Pull
    - Nagios - Pull

7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.

![monitoring](https://github.com/gaming4funNel/monitoring-hw-02/blob/main/img/1.png)

    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

## Дополнительное задание (со звездочкой*) - необязательно к выполнению

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)
    
    ---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

